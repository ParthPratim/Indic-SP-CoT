import random
from sentence_transformers import SentenceTransformer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import numpy as np
import json
import matplotlib.pyplot as plt
import argparse
from src.utils import *
import os
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm
from typing import List, Dict, Tuple


def parse_arguments():
    parser = argparse.ArgumentParser(description="self-CoT")
    parser.add_argument(
        "--task", type=str, default="hover",
        choices=list(DEFAULT_PATHS.keys()), help="dataset used for experiment"
    )
    parser.add_argument("--input_gen_file", type=str)
    parser.add_argument("--dataset_file", type=str, default=None)
    parser.add_argument(
        "--dataset_path", type=str, default=None, help="dataset used for experiment"
    )

    parser.add_argument(
        "--model_name", type=str, default="gpt-3.5-turbo-0301", help="dataset used for experiment"
    )

    parser.add_argument(
        "--method", type=str, default="zero-shot-cot",
        choices=["self-prompt", "auto-cot", "self-prompt-cot"],
        help="method used for experiment"
    )
    parser.add_argument(
        "--num_clusters", type=int, default=8, help="number of clusters"
    )
    parser.add_argument(
        "--num_demos_per_query", type=int, default=8, help="number of clusters"
    )
    parser.add_argument(
        "--output_file", type=str, default=None,
        help="use the reasoning chains generated by zero-shot-cot."
    )
    parser.add_argument(
        "--demo_save_dir", type=str, default="demos", help="where to save the constructed demonstrations"
    )
    parser.add_argument("--random_seed", type=int, default=42, help="random seed")
    parser.add_argument(
        "--encoder", type=str, default="all-MiniLM-L6-v2", help="which sentence-transformer encoder for clustering"
    )
    parser.add_argument(
        "--sampling", type=str, default="center", help="whether to sample the cluster center first"
    )
    parser.add_argument(
        "--debug", type=bool, default=True, help="debug mode"
    )
    parser.add_argument(
        "--device", type=str, default="cuda:1", help="device to use"
    )
    parser.add_argument(
        "--clustering_content", type=str, default="Q",
        choices=["Q", "QA"], help="Q: question, QA: question + answer")
    parser.add_argument(
        "--encoding_batch_size", type=int, default=128, help="batch size for encoding")
    parser.add_argument(
        "--flag", type=str, default=None, help="flag for different experiments")


    args = parser.parse_args()

    if args.dataset_path is None:
        args.dataset_path = DEFAULT_PATHS[args.task]
        print(f"[{print_now(1)}] Using default dataset path {args.dataset_path}...")

    args.demo_save_dir = os.path.join(args.demo_save_dir, args.task)

    if args.dataset_file is None:
        print(f"[{print_now(1)}] Loading default file for {args.task}...")
        args.dataset_file = os.path.join(args.dataset_path, "processed_dev.json")
        if not os.path.exists(args.dataset_file):
            raise ValueError(f"Default file {args.dataset_file} does not exist.")
    else:
        print(f"[{print_now(1)}] Loading file {args.dataset_file} for {args.task}...")

    if args.output_file is None:
        args.output_file = f"{args.method}_cluster={args.num_clusters}_content={args.clustering_content}.json"

    if args.flag is not None:
        args.output_file = args.flag + "_" + args.output_file

    print(f"output_file: {args.output_file}")

    os.makedirs(args.demo_save_dir, exist_ok=True)

    return args


def build_demo_self_prompt_cot(demo):
    self_cot = "Let's think step by step:\n"
    for j, hop in enumerate(demo["hops"]):
        self_cot += f"Step {j + 1}: {hop['question']}\n" \
                    f"Knowledge: {hop['context']}\n" \
                    f"Answer: {hop['answer']}\n"

    self_cot += f"Therefore, the final answer is: {demo['answer']}\n"

    return {
        "question": demo["question"],
        "answer": demo["answer"],
        "cot": self_cot,
        "hop_type": demo["hop_type"]
    }


def build_demo_self_prompt(demo):
    return {
        "question": demo["question"],
        "answer": f"{demo['answer']}, because {demo['evidence']}",
    }


def build_demo_auto_cot(demo):
    return {
        "question": demo["question"],
        "answer": demo['answer'],
        "cot": f"Let's think step by step. {demo['cot']}",
    }


def main(args):
    fix_seed(args.random_seed)
    encoder = SentenceTransformer(args.encoder)

    corpus = []
    raw_gen_dataset = load_json_and_jsonl_file(args.input_gen_file)
    raw_dataset = load_json_and_jsonl_file(args.dataset_file)
    queries: List[str] = []
    answers: List[List[str]] = []
    for data in raw_dataset:
        queries.append(data["question"])
        raw_ans = data["answer"]
        if isinstance(raw_ans, str):
            answers.append([raw_ans])
        else:
            answers.append(raw_ans)

    gen_dataset: List[Dict] = []

    # self-prompt-cot dataset
    for key in raw_gen_dataset:
        gen_dataset.extend(raw_gen_dataset[key])

    for data in gen_dataset:
        if args.clustering_content == "QA":
            corpus.append(data["question"] + " " + data["answer"])
        else:
            corpus.append(data["question"])

    # encode the corpus
    print("Encoding the corpus...")
    corpus_embeddings = encoder.encode(corpus, show_progress_bar=True, device=args.device, batch_size=args.encoding_batch_size)
    print("Encoding the queries...")
    query_embeddings = encoder.encode(queries, show_progress_bar=True, device=args.device, batch_size=args.encoding_batch_size)

    num_clusters = args.num_clusters

    # cluster the corpus
    clustering_model = KMeans(n_clusters=num_clusters, random_state=args.random_seed)
    clustering_model.fit(corpus_embeddings)
    cluster_labels = clustering_model.labels_

    # put corpus embeddings according to its cluster_labels into different clusters
    clusters = [[] for _ in range(num_clusters)]
    clusters_idx: List[List[int]] = [[] for _ in range(num_clusters)]
    for i, label in enumerate(cluster_labels):
        clusters[label].append(corpus_embeddings[i])
        clusters_idx[label].append(i)

    # concatenate the embeddings in each cluster
    cluster_embeddings = []
    for i in range(num_clusters):
        cluster_embeddings.append(np.stack(clusters[i], axis=0))

    # for each query embedding, find the index with max cosine similarity in each cluster
    output_demos = []
    for i in tqdm(range(len(queries)), desc="Constructing demos..."):
        query_embedding = query_embeddings[i]
        query_embedding = query_embedding.reshape(1, -1)
        most_similar_idx = []
        similar_scores = []
        for cluster_id in range(num_clusters):
            cluster_embedding = cluster_embeddings[cluster_id]
            cos_sim = cosine_similarity(query_embedding, cluster_embedding)[0]
            max_score = np.max(cos_sim)
            if (1.0 - max_score) < 1e-5:
                idx_ranking = np.argsort(cos_sim)[::-1]
                second_highest_idx = idx_ranking[1]
                most_similar_idx.append(clusters_idx[cluster_id][second_highest_idx])
                similar_scores.append(cos_sim[second_highest_idx])
            else:
                most_similar_idx.append(clusters_idx[cluster_id][np.argmax(cos_sim)])
                similar_scores.append(max_score)
        # sort most_similar_idx according to the similarity score
        most_similar_idx = sorted(enumerate(most_similar_idx), key=lambda x: similar_scores[x[0]], reverse=True)
        raw_demos = [gen_dataset[idx_tup[1]] for idx_tup in most_similar_idx]
        demos = []
        for raw_demo in raw_demos:
            if args.method == "self-prompt-cot":
                demo = build_demo_self_prompt_cot(raw_demo)
            elif args.method == "self-prompt":
                demo = build_demo_self_prompt(raw_demo)
            elif args.method == "auto-cot":
                demo = build_demo_auto_cot(raw_demo)
            else:
                raise ValueError(f"Invalid method: {args.method}")

            demos.append(demo)

        example = {
            "question": queries[i],
            "answer": answers[i],
            "demos": demos
        }
        output_demos.append(example)

    with open(os.path.join(args.demo_save_dir, args.output_file), "w") as f:
        json.dump(output_demos, f, indent=4)


if __name__ == "__main__":
    args = parse_arguments()
    main(args)
