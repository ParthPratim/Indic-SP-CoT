import random
from sentence_transformers import SentenceTransformer
from sklearn.cluster import KMeans
from sklearn.neighbors import KNeighborsClassifier
from sklearn.decomposition import PCA
import numpy as np
import json
import matplotlib.pyplot as plt
import argparse
from src.utils import *
import os
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm
from typing import List, Dict, Tuple


def parse_arguments():
    parser = argparse.ArgumentParser(description="self-CoT")
    parser.add_argument(
        "--task", type=str, default="cweb-qa",
        choices=list(DEFAULT_PATHS.keys()), help="dataset used for experiment"
    )
    parser.add_argument("--input_gen_file", type=str, default="data/self-prompt-cot/pseudo_dataset.json")
    parser.add_argument("--dataset_file", type=str, default=None)
    parser.add_argument(
        "--dataset_path", type=str, default=None, help="dataset used for experiment"
    )

    parser.add_argument(
        "--model_name", type=str, default="gpt-3.5-turbo-0301", help="dataset used for experiment"
    )

    parser.add_argument(
        "--method", type=str, default="self-prompt-cot",
        choices=["self-prompt", "auto-cot", "self-prompt-cot"],
        help="method used for experiment"
    )
    parser.add_argument(
        "--num_clusters", type=int, default=10, help="number of clusters"
    )
    parser.add_argument(
        "--knn_k", type=int, default=5, help="number of clusters"
    )
    parser.add_argument(
        "--output_file", type=str, default=None,
        help="use the reasoning chains generated by zero-shot-cot."
    )
    parser.add_argument(
        "--demo_save_dir", type=str, default="demos", help="where to save the constructed demonstrations"
    )
    parser.add_argument("--random_seed", type=int, default=42, help="random seed")
    parser.add_argument(
        "--encoder", type=str, default="all-MiniLM-L6-v2", help="which sentence-transformer encoder for clustering"
    )
    parser.add_argument(
        "--sampling", type=str, default="center", help="whether to sample the cluster center first"
    )
    parser.add_argument(
        "--debug", type=bool, default=True, help="debug mode"
    )
    parser.add_argument(
        "--device", type=str, default="cuda:0", help="device to use"
    )
    parser.add_argument(
        "--clustering_content", type=str, default="Q",
        choices=["Q", "QA"], help="Q: question, QA: question + answer")
    parser.add_argument(
        "--encoding_batch_size", type=int, default=128, help="batch size for encoding")
    parser.add_argument(
        "--flag", type=str, default=None, help="flag for different experiments")


    args = parser.parse_args()

    if args.dataset_path is None:
        args.dataset_path = DEFAULT_PATHS[args.task]
        print(f"[{print_now(1)}] Using default dataset path {args.dataset_path}...")

    args.demo_save_dir = os.path.join(args.demo_save_dir, args.task)

    if args.dataset_file is None:
        print(f"[{print_now(1)}] Loading default file for {args.task}...")
        args.dataset_file = os.path.join(args.dataset_path, "processed_dev.json")
        if not os.path.exists(args.dataset_file):
            raise ValueError(f"Default file {args.dataset_file} does not exist.")
    else:
        print(f"[{print_now(1)}] Loading file {args.dataset_file} for {args.task}...")

    if args.output_file is None:
        args.output_file = f"{args.method}_c-{args.num_clusters}_{args.clustering_content}_k-{args.knn_k}.json"

    if args.flag is not None:
        args.output_file = args.flag + "_" + args.output_file

    print(f"output_file: {args.output_file}")

    os.makedirs(args.demo_save_dir, exist_ok=True)

    return args


def build_demo_self_prompt_cot(demo):
    self_cot = "Let's think step by step:\n"
    for j, hop in enumerate(demo["hops"]):
        # evidence only
        evidence = hop['evidence'].replace('as stated in the passage', '').replace('The passage states that ', '')
        evidence = evidence.replace('as mentioned in the passage', '').replace('The passage mentions that ', '').replace(' in the passage', '')
        self_cot += f"Step {j + 1}: {evidence}\n"

        # # without knowledge
        # self_cot += f"Step {j + 1}: {hop['question']}\n" \
        #             f"Answer in just one entity: {hop['answer']}\n"

        # with knowledge
        # self_cot += f"Step {j + 1}: {hop['question']}\n" \
        #             f"Knowledge: {hop['context']}\n" \
        #             f"Answer: {hop['answer']}\n"

    self_cot += f"Therefore, the final answer in just one entity is: {demo['answer']}\n"

    return {
        "question": demo["question"],
        "answer": demo["answer"],
        "cot": self_cot,
        "hop_type": demo["hop_type"]
    }


def build_demo_self_prompt(demo):
    return {
        "question": demo["question"],
        "answer": f"{demo['answer']}, because {demo['evidence']}",
    }


def build_demo_auto_cot(demo):
    return {
        "question": demo["question"],
        "answer": demo['answer'],
        "cot": f"Let's think step by step. {demo['cot']}",
    }


def cluster_and_embed(num_clusters: int, corpus_embeddings, seed: int = 42):
    # cluster the corpus
    clustering_model = KMeans(n_clusters=num_clusters, random_state=seed)
    clustering_model.fit(corpus_embeddings)
    cluster_labels = clustering_model.labels_

    # put corpus embeddings according to its cluster_labels into different clusters
    clusters = [[] for _ in range(num_clusters)]
    clusters_idx: List[List[int]] = [[] for _ in range(num_clusters)]
    for i, label in enumerate(cluster_labels):
        clusters[label].append(corpus_embeddings[i])
        clusters_idx[label].append(i)

    # concatenate the embeddings in each cluster
    cluster_embeddings = []
    for i in range(num_clusters):
        cluster_embeddings.append(np.stack(clusters[i], axis=0))

    return cluster_embeddings, clusters_idx


def main(args):
    fix_seed(args.random_seed)
    encoder = SentenceTransformer(args.encoder)

    corpus = []
    raw_gen_dataset = load_json_and_jsonl_file(args.input_gen_file)
    raw_dataset = load_json_and_jsonl_file(args.dataset_file)
    queries: List[str] = []
    answers: List[List[str]] = []
    for data in raw_dataset:
        queries.append(data["question"])
        raw_ans = data["answer"]
        if isinstance(raw_ans, str):
            answers.append([raw_ans])
        else:
            answers.append(raw_ans)

    gen_dataset: List[Dict] = []
    gen_labels: List[int] = []

    if args.method == "self-prompt-cot":
        # self-prompt-cot dataset
        for key in raw_gen_dataset:
            for data in raw_gen_dataset[key]:
                gen_dataset.append(data)
                gen_labels.append(TYPE_MAPPING[key])
    else:
        # self-prompt or auto-cot dataset
        for data in raw_gen_dataset:
            gen_dataset.append(data)

    for data in gen_dataset:
        if args.clustering_content == "QA":
            corpus.append(data["question"] + " " + data["answer"])
        else:
            corpus.append(data["question"])

    # encode the corpus
    print("Encoding the corpus...")
    corpus_embeddings = encoder.encode(corpus, show_progress_bar=True, device=args.device, batch_size=args.encoding_batch_size)
    print("Encoding the queries...")
    query_embeddings = encoder.encode(queries, show_progress_bar=True, device=args.device, batch_size=args.encoding_batch_size)

    num_clusters = args.num_clusters

    if args.method == "self-prompt-cot":
        cluster_embeddings = []
        cluster_labels = []
        gen_labels: np.ndarray = np.array(gen_labels)
        cluster_dataset = []
        knn_model = KNeighborsClassifier(n_neighbors=args.knn_k)
        knn_model.fit(corpus_embeddings, gen_labels)
        for type_id in TYPE_MAPPING.values():
            # get the embeddings of the demos of the same type
            type_mask = gen_labels == type_id
            type_embeddings = corpus_embeddings[type_mask]
            cluster_dataset.append([gen_dataset[i] for i, mask in enumerate(type_mask) if mask])
            type_cluster_embeddings, type_cluster_idx = cluster_and_embed(num_clusters, type_embeddings)
            cluster_embeddings.append(type_cluster_embeddings)
            cluster_labels.append(type_cluster_idx)

        # iterate over questions, determine the type of the question with knn and find the most similar demo in each cluster
        output_demos = []
        for i in tqdm(range(len(queries)), desc="Constructing demos..."):
            query_embedding = query_embeddings[i]
            query_embedding = query_embedding.reshape(1, -1)
            # find the type of the question
            type_id = knn_model.predict(query_embedding)[0]
            # find the most similar demo in each cluster
            most_similar_idx = []
            similar_scores = []
            for cluster_id in range(num_clusters):
                cluster_embedding = cluster_embeddings[type_id][cluster_id]
                cos_sim = cosine_similarity(query_embedding, cluster_embedding)[0]
                max_score = np.max(cos_sim)
                if (1.0 - max_score) < 1e-5:
                    idx_ranking = np.argsort(cos_sim)[::-1]
                    second_highest_idx = idx_ranking[1]
                    most_similar_idx.append(cluster_labels[type_id][cluster_id][second_highest_idx])
                    similar_scores.append(cos_sim[second_highest_idx])
                else:
                    most_similar_idx.append(cluster_labels[type_id][cluster_id][np.argmax(cos_sim)])
                    similar_scores.append(max_score)
            # find the most similar demo among all clusters
            most_similar_idx = sorted(enumerate(most_similar_idx), key=lambda x: similar_scores[x[0]], reverse=True)
            similar_scores = sorted(similar_scores, reverse=True)
            raw_demos = [cluster_dataset[type_id][idx_tup[1]] for idx_tup in most_similar_idx]
            demos = []
            for idx, raw_demo in enumerate(raw_demos):
                demo = build_demo_self_prompt_cot(raw_demo)
                demo["score"] = str(similar_scores[idx])
                demos.append(demo)
            output_demos.append({
                "question": queries[i],
                "answer": answers[i],
                "demos": demos
            })
    else:
        cluster_embeddings, clusters_idx = cluster_and_embed(num_clusters, corpus_embeddings)
        # for each query embedding, find the index with max cosine similarity in each cluster
        output_demos = []
        for i in tqdm(range(len(queries)), desc="Constructing demos..."):
            query_embedding = query_embeddings[i]
            query_embedding = query_embedding.reshape(1, -1)
            most_similar_idx = []
            similar_scores = []
            for cluster_id in range(num_clusters):
                cluster_embedding = cluster_embeddings[cluster_id]
                cos_sim = cosine_similarity(query_embedding, cluster_embedding)[0]
                max_score = np.max(cos_sim)
                if (1.0 - max_score) < 1e-5:
                    idx_ranking = np.argsort(cos_sim)[::-1]
                    second_highest_idx = idx_ranking[1]
                    most_similar_idx.append(clusters_idx[cluster_id][second_highest_idx])
                    similar_scores.append(cos_sim[second_highest_idx])
                else:
                    most_similar_idx.append(clusters_idx[cluster_id][np.argmax(cos_sim)])
                    similar_scores.append(max_score)
            # sort most_similar_idx according to the similarity score
            most_similar_idx = sorted(enumerate(most_similar_idx), key=lambda x: similar_scores[x[0]], reverse=True)
            raw_demos = [gen_dataset[idx_tup[1]] for idx_tup in most_similar_idx]
            demos = []
            for raw_demo in raw_demos:
                if args.method == "self-prompt":
                    demo = build_demo_self_prompt(raw_demo)
                elif args.method == "auto-cot":
                    demo = build_demo_auto_cot(raw_demo)
                else:
                    raise ValueError(f"Invalid method: {args.method}")

                demos.append(demo)

            example = {
                "question": queries[i],
                "answer": answers[i],
                "demos": demos
            }
            output_demos.append(example)

    with open(os.path.join(args.demo_save_dir, args.output_file), "w") as f:
        json.dump(output_demos, f, indent=4)


if __name__ == "__main__":
    args = parse_arguments()
    main(args)
